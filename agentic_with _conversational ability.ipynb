{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578880b2-56b3-462c-bc0c-cce13e27fd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a2a596-951f-46b9-8b43-1f4954fe75fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd40a9cf-1302-44a4-898f-f23e3cb029f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "978a1feb-a696-4750-b658-a7739cb3f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e61498e7-12ae-4205-a8a6-7955c5d1ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb12e41-049c-4b6d-8467-92dc9cf5240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "from textwrap import dedent\n",
    "from crewai import Agent, Task, Crew,LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf55fd95-8d42-4664-b803-63cbbdb53a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2af608a33f9483580e00fabb6ac4da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\aravi\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae24bd0d662c4f2b84ba143d90a16f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e2dd7c8b3148569800d87d2cb9fe29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936ee7da73634845af365babdc4d348e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4519054c0fe4b509d77febc46cac8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a08c8502e3c4cc9852f2fce1e43456a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c1061a8b7c451997d925c9a831df47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28832d24f074cf589007e94a231c178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47226abab9bd4baea23d7dfc7f264f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f0ba5c23a44182b35f07a57dcd0845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba589069f3e4889998e5949c8fa1b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "EMBEDDING_MODEL = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7586c35-4976-48b4-929c-161da5840880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PDFPlumberLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e81c1d-08bc-489f-8555-b658022b55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca73c6b0-e3ee-4d50-afbe-ea01981ef7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c1d17ec-821c-429d-b344-6c012b710ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE_MODEL = OllamaLLM(model=\"deepseek-r1:1.5b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40b07952-729e-4c77-ad98-226f0fda0223",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_STORAGE_PATH = \"C:\\\\Users\\\\aravi\\\\Downloads\\\\pdfwrite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a7d9164-ffdb-4b74-9a77-20b6a0eefb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = EMBEDDING_MODEL.get_sentence_embedding_dimension()\n",
    "DOCUMENT_VECTOR_DB = faiss.IndexFlatL2(dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd22c18a-6a05-4ad2-9677-c4e8c849523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc535b64-abaa-4a86-86f1-31f680adf698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_uploaded_file(uploaded_file, filename):\n",
    "    \"\"\"Saves uploaded PDF to a local directory.\"\"\"\n",
    "    file_path = os.path.join(PDF_STORAGE_PATH, filename)\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        file.write(uploaded_file.read())\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23a524b7-4fa2-4206-b3f3-3e3aec86d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_documents(file_path):\n",
    "    \"\"\"Loads documents from a PDF file.\"\"\"\n",
    "    document_loader = PDFPlumberLoader(file_path)\n",
    "    return document_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03ff92f7-663a-4148-8d8b-5360749e24cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_documents(raw_documents):\n",
    "    \"\"\"Splits documents into smaller text chunks.\"\"\"\n",
    "    text_processor = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=300,\n",
    "        add_start_index=True\n",
    "    )\n",
    "    return text_processor.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10d74a97-b3c2-4653-93a0-cf881dd62745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_documents(document_chunks):\n",
    "    \"\"\"Embeds documents, adds them to FAISS, and stores text mappings.\"\"\"\n",
    "    embeddings = np.array(EMBEDDING_MODEL.encode(\n",
    "        [doc.page_content for doc in document_chunks], \n",
    "        convert_to_numpy=True, \n",
    "        normalize_embeddings=True\n",
    "    ), dtype=np.float32)\n",
    "\n",
    "    start_id = len(doc_store)  # Start index for new documents\n",
    "    for i, doc in enumerate(document_chunks):\n",
    "        doc_store[start_id + i] = doc.page_content  # Store text\n",
    "    \n",
    "    DOCUMENT_VECTOR_DB.add(embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8aa91078-5127-49b4-912d-e26abad0bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_related_documents(query, k=2):\n",
    "    \"\"\"Finds the most relevant documents using FAISS similarity search.\"\"\"\n",
    "    query_embedding = np.array(EMBEDDING_MODEL.encode(\n",
    "        [query], \n",
    "        convert_to_numpy=True, \n",
    "        normalize_embeddings=True\n",
    "    ), dtype=np.float32)\n",
    "\n",
    "    _, indices = DOCUMENT_VECTOR_DB.search(query_embedding, k)\n",
    "\n",
    "    results = [doc_store[idx] for idx in indices[0] if idx in doc_store]\n",
    "    return results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d3ca00b-b6e8-49e5-b339-88bb7bae2bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_answer(user_query,related_docs):\n",
    "    \"\"\"Finds related documents, formats a prompt, and generates an AI response.\"\"\"\n",
    "    \n",
    "\n",
    "    if not related_docs:\n",
    "        return [\"I'm sorry, but I couldn't find an answer in the provided document.\", \"\"]\n",
    "\n",
    "    context_text = \"\\n\\n\".join([doc for doc in related_docs])\n",
    "    prompt = prompt_template(user_query, context_text)\n",
    "    ai_response1 = LANGUAGE_MODEL.invoke(prompt)\n",
    "    ai_response2 = LANGUAGE_MODEL.invoke(f\"response from an AI model {ai_response1} refine the response to clear,concise and meaninglful by without changing or avoiding any information \")\n",
    "    ai_response1 = re.split(r\"</think>\\s*\", ai_response1, maxsplit=1)[-1].strip()\n",
    "    ai_response2 = re.split(r\"</think>\\s*\", ai_response2, maxsplit=1)[-1].strip()\n",
    "    return [ai_response1,ai_response2, context_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf3886af-c49b-44fc-96c8-fbbfd87a544d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF saved at: C:\\Users\\aravi\\Downloads\\pdfwrite\\mypdf.pdf\n"
     ]
    }
   ],
   "source": [
    "uploaded_pdf = \"C:\\\\Users\\\\aravi\\\\Downloads\\\\mypdf.pdf\"\n",
    "if uploaded_pdf:\n",
    "    filename = os.path.basename(uploaded_pdf)\n",
    "    file_path = save_uploaded_file(open(uploaded_pdf, \"rb\"), filename)\n",
    "    print(f\"PDF saved at: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb08660f-b346-4a8e-870b-2d5a5afbc867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process document\n",
    "raw_docs = load_pdf_documents(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7378fe9e-fe3e-4b88-82d0-b3566dcbc148",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_chunks = chunk_documents(raw_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01c6cc5a-f4f2-4e0a-adc0-c25f5fdf5bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_documents(processed_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6a74b0f-0f57-4399-8b54-f9959cbad23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User query example\n",
    "user_input = \"How to switch from Airtel Prepaid to Postpaid?\"\n",
    "related_docs = find_related_documents(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3460b1a5-a28a-4cd8-a63d-58454d70fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"D:\\\\New folder\"\n",
    "faiss_index_path = os.path.join(save_dir, \"faiss_index.bin\")\n",
    "metadata = {\"num_vectors\": DOCUMENT_VECTOR_DB.ntotal, \"dimension\": DOCUMENT_VECTOR_DB.d}\n",
    "faiss.write_index(DOCUMENT_VECTOR_DB, faiss_index_path)\n",
    "with open(\"metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metadata, f)\n",
    "file_path = \"D:\\\\New folder\"  # Folder path\n",
    "file_name = \"dictionary.pkl\"  # File name\n",
    "dict_path = os.path.join(file_path, file_name)  \n",
    "with open(dict_path, \"wb\") as file:\n",
    "    pickle.dump(doc_store, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75a1293a-297a-4f56-9dd4-6e7ef7f5fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = faiss.read_index(faiss_index_path)\n",
    "with open(dict_path, \"rb\") as file:\n",
    "    doc_store = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6d78ec62-1f43-4ebc-921e-5d62a1452692",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalesCrewAgents:\n",
    "    def __init__(self):\n",
    "        llm = \"gemini/gemini-1.5-flash\"\n",
    "        self.llm = LLM(model=llm)\n",
    "\n",
    "    \n",
    "    def master_agent(self):\n",
    "        return Agent(\n",
    "            role=\"Master Coordinator and Query Dispatcher\",\n",
    "            goal=dedent(\"\"\"\n",
    "            The Master Agent is responsible for receiving user queries, classifying them based on intent, \n",
    "            and dispatching them to the appropriate specialized agents. It ensures seamless communication \n",
    "            between agents and optimizes query handling to provide fast and accurate responses.\n",
    "            \"\"\"),\n",
    "            backstory=dedent(\"\"\"\n",
    "            Designed as the central intelligence of an agentic AI architecture, the Master Agent was built \n",
    "            to orchestrate a network of specialized sub-agents. It has been trained with a deep understanding \n",
    "            of various domains and acts as a mediator, ensuring that every query reaches the most capable agent.\n",
    "            Over time, it has evolved to learn from past interactions, refining its classification techniques \n",
    "            and optimizing agent collaboration for efficiency.\n",
    "            \"\"\"),\n",
    "            llm = self.llm\n",
    "        )\n",
    "    def conversational_agent(self):\n",
    "        return Agent(\n",
    "            role=dedent(\"\"\"\n",
    "            Conversational AI Agent - Responsible for understanding, generating, and maintaining a natural \n",
    "            language conversation with the user. It retrieves relevant context from stored documents and \n",
    "            provides intelligent, context-aware responses.\n",
    "            \"\"\"),\n",
    "            goal=dedent(\"\"\"\n",
    "            The goal of the Conversational Agent is to engage with the user in a meaningful and informative \n",
    "            manner. It should understand user queries, retrieve relevant information from the document \n",
    "            store, and generate responses that are coherent, accurate, and contextually relevant.\n",
    "            \"\"\"),\n",
    "            backstory=dedent(\"\"\"\n",
    "            The Conversational Agent was developed as a key component of the agentic AI system, designed \n",
    "            to facilitate human-like interactions. Equipped with an advanced embedding model and a \n",
    "            high-performance vector database, it efficiently retrieves knowledge from stored documents \n",
    "            and crafts responses based on contextual understanding. Over time, it has improved its \n",
    "            conversational skills by learning from past interactions, making it a highly adaptive and \n",
    "            responsive entity in the system.\n",
    "            \"\"\"),\n",
    "            llm = self.llm\n",
    "        )\n",
    "\n",
    "class SalesCreWTasks:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def query_classification(self,user_input,master_agent):#,master_agent,conversational_agent,develop_conversation,recommender_agent,recommend_products,generator_agent,generate_images):\n",
    "        return Task(\n",
    "            description=dedent(f\"\"\"\n",
    "            this is the user input {user_input} based on this input the agent should be returned no other explaination needed just\n",
    "            return the returned agent and task\n",
    "            these are the agents and their respective tasks: \n",
    "            agent1 is conversational_agent and its Task is develop_conversation\n",
    "            agent2 is recommender_agent and its Task is recommmend_products\n",
    "            agent3 is generator_agent and its Task is generate_images\n",
    "            these are the agents and tasks based on the query initialize the agent create crew fo that\n",
    "            This task involves analyzing the given input, which could be either a user query or detailed \n",
    "            product information. The goal is to classify the input into a predefined category such as \n",
    "            \"Database Query\", \"Machine Learning Request\", \"Product Information Processing\", or any other \n",
    "            relevant domain. Once classified, the task triggers the appropriate listening agent to handle \n",
    "            the request efficiently.\n",
    "            \"\"\"),\n",
    "            expected_output=dedent(\"you should return the respective agent and task it classified to the user_input like onversational_agent nothing more than that, just the name\"),\n",
    "            agent=master_agent,\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def develop_conversation(self,user_input,vector_db,doc_store,EMBEDDING_MODEL,conversational_agent):\n",
    "        query_embedding = np.array(EMBEDDING_MODEL.encode(\n",
    "            [user_input], \n",
    "            convert_to_numpy=True, \n",
    "            normalize_embeddings=True\n",
    "        ), dtype=np.float32)\n",
    "        _, indices = vector_db.search(query_embedding, 2)\n",
    "        context = [doc_store[idx] for idx in indices[0] if idx in doc_store]\n",
    "        \n",
    "        return Task(\n",
    "            description=dedent(f\"\"\"\n",
    "            context : {context} the first and foremost thing is, you should not answer to any queries beyound the context if the context given to the query is not relevent just give the response as i dont know about what your asking \n",
    "\n",
    "            This task involves generating a natural language response to a user query by retrieving \n",
    "            relevant context from a vectorized document store. The input query is transformed into an \n",
    "            embedding, and a similarity search is performed against the vector database to find the \n",
    "            most relevant documents. The retrieved context is then used to generate a meaningful response.\n",
    "            \"\"\"),\n",
    "            expected_output=dedent(\"make word to word conversation\"),\n",
    "            agent = conversational_agent\n",
    "        )\n",
    "\n",
    "class SalesCrew:\n",
    "    def __init__(self,vector_db,doc_store,EMBEDDING_MODEL):\n",
    "        self.EMBEDDING_MODEL = EMBEDDING_MODEL\n",
    "        self.vector_db = vector_db\n",
    "        self.doc_store = doc_store\n",
    "    def run(self,input):\n",
    "        agents = SalesCrewAgents()\n",
    "        tasks = SalesCreWTasks()\n",
    "        master_agent = agents.master_agent()\n",
    "        conversational_agent = agents.conversational_agent()\n",
    "\n",
    "        develop_conversation = tasks.develop_conversation(input,self.vector_db,self.doc_store,self.EMBEDDING_MODEL,conversational_agent)\n",
    "        query_classification = tasks.query_classification(input,master_agent)\n",
    "        crew = Crew(\n",
    "            agents = [master_agent],\n",
    "            tasks = [query_classification],\n",
    "            verbose = True\n",
    "        )\n",
    "        \n",
    "        result = crew.kickoff().raw\n",
    "        \n",
    "        if result == 'conversational_agent':\n",
    "            crew1 = Crew(\n",
    "                agents = [conversational_agent],\n",
    "                tasks = [develop_conversation],\n",
    "                verbose = True\n",
    "            )\n",
    "            return crew1.kickoff()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cb01149d-0009-4f6f-9397-0cad353d86fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mMaster Coordinator and Query Dispatcher\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m\n",
      "this is the user input How to check Airtel DTH balance? based on this input the agent should be returned no other explaination needed just\n",
      "return the returned agent and task\n",
      "these are the agents and their respective tasks: \n",
      "agent1 is conversational_agent and its Task is develop_conversation\n",
      "agent2 is recommender_agent and its Task is recommmend_products\n",
      "agent3 is generator_agent and its Task is generate_images\n",
      "these are the agents and tasks based on the query initialize the agent create crew fo that\n",
      "This task involves analyzing the given input, which could be either a user query or detailed \n",
      "product information. The goal is to classify the input into a predefined category such as \n",
      "\"Database Query\", \"Machine Learning Request\", \"Product Information Processing\", or any other \n",
      "relevant domain. Once classified, the task triggers the appropriate listening agent to handle \n",
      "the request efficiently.\n",
      "\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mMaster Coordinator and Query Dispatcher\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "conversational_agent\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92m\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m\n",
      "context : ['The Code has to be sent to 54325 from your registered mobile\\n7) How to check Airtel DTH balance?\\nYou can check the Airtel DTH Balance in the following 3 ways:\\nSMS ‘BAL’ to 54325 from your Registered Mobile Number\\nFrom your registered mobile give a missed call to 81300-81300\\nOn the Airtel Thanks App on the Services page, the DTH account has the balance\\n8) Which Is The Best DTH HD Connection?\\nAirtel is considered the best DTH HD connection in India by customers and industry experts because of the cutting-edge features that are\\nincluded in their offerings. Another reason to make Airtel DTH the best in the market is the attractive packages and pricing of its packs.', 'Enter the recharge amount or browse for plans\\nConfirm and pay through Airtel Payments Bank, Debit/Credit card or Netbanking\\n5) How to change Airtel DTH HD Plan?\\nYou can easily Change the Airtel DTH HD plan by logging into your account on the Airtel website and choosing the DTH account. You can then\\ngo to the ‘Connections’ tab and ‘Change Base Pack’ option. You can then choose one of the preset plans or make your own pack.\\n6) How to select channels in Airtel DTH HD?\\nYou can select channels for your Airtel DTH HD through the TV set itself:\\nTurn on Airtel Digital TV\\nPut on the Channel No. 998\\nThe On-Screen instructions will guide you to make the choice\\nConfirmation code is displayed once done\\nThe Code has to be sent to 54325 from your registered mobile\\n7) How to check Airtel DTH balance?\\nYou can check the Airtel DTH Balance in the following 3 ways:\\nSMS ‘BAL’ to 54325 from your Registered Mobile Number\\nFrom your registered mobile give a missed call to 81300-81300'] the first and foremost thing is, you should not answer to any queries beyound the context if the context given to the query is not relevent just give the response as i dont know about what your asking \n",
      "\n",
      "This task involves generating a natural language response to a user query by retrieving \n",
      "relevant context from a vectorized document store. The input query is transformed into an \n",
      "embedding, and a similarity search is performed against the vector database to find the \n",
      "most relevant documents. The retrieved context is then used to generate a meaningful response.\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92m\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "To check your Airtel DTH balance, you can use one of these three methods:\n",
      "\n",
      "1.  Send an SMS with the word \"BAL\" to 54325 from your registered mobile number.\n",
      "2.  Give a missed call to 81300-81300 from your registered mobile number.\n",
      "3.  Check your DTH account balance on the Airtel Thanks App, under the Services page.\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_MODEL = EMBEDDING_MODEL\n",
    "vector_db = vector_db\n",
    "doc_store = doc_store\n",
    "# user_interaction = \"SAMSUNG Galaxy S24 Ultra 5G (Titanium Gray, 512 GB)  (12 GB RAM)\"\n",
    "user_interaction = \"How to check Airtel DTH balance?\"\n",
    "salescrew = SalesCrew(vector_db,doc_store,EMBEDDING_MODEL)\n",
    "res = salescrew.run(user_interaction)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d3403e-15eb-43e9-b12c-c986ff786d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from crewai import Agent, Task, Crew,LLM\n",
    "\n",
    "\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyCEbfbYNew93-vVFmnT47MBombG7x2sPJU\"\n",
    "llm = \"gemini/gemini-1.5-flash\"\n",
    "llm = LLM(model=llm)\n",
    "\n",
    "# Define the Agent\n",
    "retrieval_agent = Agent(\n",
    "    role=\"AI Research Assistant\",\n",
    "    goal=\"Retrieve and provide the most relevant information based on user queries.\",\n",
    "    backstory=\"You are an AI-powered assistant designed to search through a database and provide users with the best-matching responses.\",\n",
    "    llm = llm,\n",
    "    verbose=True  # Enable debugging\n",
    ")\n",
    "\n",
    "# Define retrieval function\n",
    "def retrieve_answer(query):\n",
    "    \"\"\"Retrieve the most relevant answer from FAISS\"\"\"\n",
    "    # Convert query to vector\n",
    "    query_embedding = np.array(\n",
    "        EMBEDDING_MODEL.encode([query], convert_to_numpy=True, normalize_embeddings=True), \n",
    "        dtype=np.float32\n",
    "    )\n",
    "\n",
    "    # Search in FAISS\n",
    "    _, indices = vector_db.search(query_embedding, k=3)  # Retrieve top 3 results\n",
    "\n",
    "    # Retrieve context from document store\n",
    "    context = [doc_store[idx] for idx in indices[0] if idx in doc_store]\n",
    "\n",
    "    # Format response\n",
    "    if context:\n",
    "        return \"\\n\\n\".join(context)\n",
    "    else:\n",
    "        return \"No relevant information found.\"\n",
    "\n",
    "# Define Task for the Agent\n",
    "# Define Task for the Agent\n",
    "query_task = Task(\n",
    "    description=f\"Process user query: {query} and retrieve the best response. first and foremost thing is dont answer anything beyound the context you retrived from the retrieve_answer function\",\n",
    "    agent=retrieval_agent,\n",
    "    function=retrieve_answer,\n",
    "    expected_output=\"The most relevant answer retrieved from the knowledge base.\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Define Crew\n",
    "chatbot_crew = Crew(\n",
    "    agents=[retrieval_agent],\n",
    "    tasks=[query_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Gradio Chatbot UI\n",
    "def chatbot_interface(user_query):\n",
    "    return chatbot_crew.kickoff(inputs={\"query\": user_query})  # Use a dictionary\n",
    "\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=chatbot_interface,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"AI Chatbot\",\n",
    "    description=\"Ask any question, and the AI will retrieve the best answer!\"\n",
    ")\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
