{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578880b2-56b3-462c-bc0c-cce13e27fd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd40a9cf-1302-44a4-898f-f23e3cb029f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "978a1feb-a696-4750-b658-a7739cb3f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61498e7-12ae-4205-a8a6-7955c5d1ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf55fd95-8d42-4664-b803-63cbbdb53a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "EMBEDDING_MODEL = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7586c35-4976-48b4-929c-161da5840880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PDFPlumberLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21e81c1d-08bc-489f-8555-b658022b55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca73c6b0-e3ee-4d50-afbe-ea01981ef7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "063d586c-5233-4c68-a0e1-6e187f27b357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING_MODEL = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "EMBEDDING_MODEL = SentenceTransformer(\"all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c1d17ec-821c-429d-b344-6c012b710ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE_MODEL = OllamaLLM(model=\"deepseek-r1:1.5b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40b07952-729e-4c77-ad98-226f0fda0223",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_STORAGE_PATH = \"C:\\\\Users\\\\aravi\\\\Downloads\\\\pdfwrite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a7d9164-ffdb-4b74-9a77-20b6a0eefb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = EMBEDDING_MODEL.get_sentence_embedding_dimension()\n",
    "DOCUMENT_VECTOR_DB = faiss.IndexFlatL2(dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd22c18a-6a05-4ad2-9677-c4e8c849523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc535b64-abaa-4a86-86f1-31f680adf698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_uploaded_file(uploaded_file, filename):\n",
    "    \"\"\"Saves uploaded PDF to a local directory.\"\"\"\n",
    "    file_path = os.path.join(PDF_STORAGE_PATH, filename)\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        file.write(uploaded_file.read())\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23a524b7-4fa2-4206-b3f3-3e3aec86d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_documents(file_path):\n",
    "    \"\"\"Loads documents from a PDF file.\"\"\"\n",
    "    document_loader = PDFPlumberLoader(file_path)\n",
    "    return document_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03ff92f7-663a-4148-8d8b-5360749e24cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_documents(raw_documents):\n",
    "    \"\"\"Splits documents into smaller text chunks.\"\"\"\n",
    "    text_processor = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=300,\n",
    "        add_start_index=True\n",
    "    )\n",
    "    return text_processor.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10d74a97-b3c2-4653-93a0-cf881dd62745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_documents(document_chunks):\n",
    "    \"\"\"Embeds documents, adds them to FAISS, and stores text mappings.\"\"\"\n",
    "    embeddings = np.array(EMBEDDING_MODEL.encode(\n",
    "        [doc.page_content for doc in document_chunks], \n",
    "        convert_to_numpy=True, \n",
    "        normalize_embeddings=True\n",
    "    ), dtype=np.float32)\n",
    "\n",
    "    start_id = len(doc_store)  # Start index for new documents\n",
    "    for i, doc in enumerate(document_chunks):\n",
    "        doc_store[start_id + i] = doc.page_content  # Store text\n",
    "    \n",
    "    DOCUMENT_VECTOR_DB.add(embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8aa91078-5127-49b4-912d-e26abad0bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_related_documents(query, k=2):\n",
    "    \"\"\"Finds the most relevant documents using FAISS similarity search.\"\"\"\n",
    "    query_embedding = np.array(EMBEDDING_MODEL.encode(\n",
    "        [query], \n",
    "        convert_to_numpy=True, \n",
    "        normalize_embeddings=True\n",
    "    ), dtype=np.float32)\n",
    "\n",
    "    _, indices = DOCUMENT_VECTOR_DB.search(query_embedding, k)\n",
    "\n",
    "    results = [doc_store[idx] for idx in indices[0] if idx in doc_store]\n",
    "    return results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de3c421a-0cdb-4863-8c90-b96f8ec94244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def expand_query(query):\n",
    "#     \"\"\"Expands a short query into a more detailed search phrase.\"\"\"\n",
    "#     expansion_prompt = f\"\"\"\n",
    "#     Given this short user query: \"{query}\"\n",
    "#     Expand it into a more detailed question for better document retrieval.\n",
    "#     \"\"\"\n",
    "#     return LANGUAGE_MODEL.invoke(expansion_prompt)\n",
    "\n",
    "def prompt_template(user_query, context_text):\n",
    "    \"\"\"Formats user query and document context into a structured prompt.\"\"\"\n",
    "    return f\"\"\"You are an intelligent assistant tasked with answering user queries strictly based on the provided document.\n",
    "\n",
    "### **Context (Extracted from Document)**\n",
    "{context_text}\n",
    "\n",
    "### **User Query**\n",
    "{user_query}\n",
    "\n",
    "### **Instructions for Answering**\n",
    "- Use only the provided document content to generate a response.\n",
    "- Do **not** introduce any external information or assumptions.\n",
    "- Extract relevant details from the document and structure them into a **coherent, well-formed response**.\n",
    "- Ensure the response is **clear and readable**, maintaining natural formatting without unnecessary line breaks (`\\n`).\n",
    "- Do **not** insert extra newlines unless they are essential for meaning or readability.\n",
    "- Avoid excessive spacing, unnatural paragraph breaks, or disjointed formatting.\n",
    "- If special characters like `\\n` are found in the extracted content, **omit them unless needed for clarity**.\n",
    "- If no relevant information is available, respond with: \"I'm sorry, but I couldn't find an answer in the provided document.\"\n",
    "- Do not provide explanations or context beyond what is necessary to answer the query.\n",
    "\n",
    "### **Final Answer (Ensure clear, natural formatting without unnecessary newlines)**\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d3ca00b-b6e8-49e5-b339-88bb7bae2bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(user_query,related_docs):\n",
    "    \"\"\"Finds related documents, formats a prompt, and generates an AI response.\"\"\"\n",
    "    \n",
    "\n",
    "    if not related_docs:\n",
    "        return [\"I'm sorry, but I couldn't find an answer in the provided document.\", \"\"]\n",
    "\n",
    "    context_text = \"\\n\\n\".join([doc for doc in related_docs])\n",
    "    prompt = prompt_template(user_query, context_text)\n",
    "    ai_response1 = LANGUAGE_MODEL.invoke(prompt)\n",
    "    ai_response2 = LANGUAGE_MODEL.invoke(f\"response from an AI model {ai_response1} refine the response to clear,concise and meaninglful by without changing or avoiding any information \")\n",
    "    ai_response1 = re.split(r\"</think>\\s*\", ai_response1, maxsplit=1)[-1].strip()\n",
    "    ai_response2 = re.split(r\"</think>\\s*\", ai_response2, maxsplit=1)[-1].strip()\n",
    "    return [ai_response1,ai_response2, context_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf3886af-c49b-44fc-96c8-fbbfd87a544d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF saved at: C:\\Users\\aravi\\Downloads\\pdfwrite\\mypdf.pdf\n"
     ]
    }
   ],
   "source": [
    "uploaded_pdf = \"C:\\\\Users\\\\aravi\\\\Downloads\\\\mypdf.pdf\"\n",
    "if uploaded_pdf:\n",
    "    filename = os.path.basename(uploaded_pdf)\n",
    "    file_path = save_uploaded_file(open(uploaded_pdf, \"rb\"), filename)\n",
    "    print(f\"PDF saved at: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb08660f-b346-4a8e-870b-2d5a5afbc867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process document\n",
    "raw_docs = load_pdf_documents(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7378fe9e-fe3e-4b88-82d0-b3566dcbc148",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_chunks = chunk_documents(raw_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01c6cc5a-f4f2-4e0a-adc0-c25f5fdf5bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_documents(processed_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6a74b0f-0f57-4399-8b54-f9959cbad23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User query example\n",
    "user_input = \"How to switch from Airtel Prepaid to Postpaid?\"\n",
    "related_docs = find_related_documents(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62909f48-fbf1-4cc3-bfc4-44ee3c9946de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_response = generate_answer(user_input,related_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e54243-2fae-4a63-9794-46ce06a9d799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
